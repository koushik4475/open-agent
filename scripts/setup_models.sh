#!/usr/bin/env bash
# ================================================================
# scripts/setup_models.sh
# One-command setup for the local LLM runtime.
# Run this ONCE before starting the agent.
# ================================================================

set -e

echo "=============================================="
echo "  OpenAgent â€” Model Setup Script"
echo "=============================================="
echo ""

# â”€â”€â”€ 1. Check if Ollama is installed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if command -v ollama &> /dev/null; then
    echo "âœ… Ollama is already installed."
    OLLAMA_VERSION=$(ollama version 2>/dev/null || echo "unknown")
    echo "   Version: $OLLAMA_VERSION"
else
    echo "ðŸ“¥ Ollama not found. Installing..."
    echo ""

    # Detect OS
    OS=$(uname -s)
    case "$OS" in
        Linux)
            echo "   Detected: Linux"
            curl -fsSL https://ollama.ai/install.sh | sh
            ;;
        Darwin)
            echo "   Detected: macOS"
            echo "   Please download Ollama from: https://ollama.ai/download/mac"
            echo "   Then run this script again."
            exit 1
            ;;
        *)
            echo "   Detected: $OS"
            echo "   Please install Ollama manually: https://ollama.ai"
            exit 1
            ;;
    esac

    echo ""
    echo "âœ… Ollama installed successfully."
fi

echo ""

# â”€â”€â”€ 2. Start Ollama service â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo "ðŸ”„ Starting Ollama service..."
ollama serve &
OLLAMA_PID=$!
sleep 2  # Give it a moment to start

# â”€â”€â”€ 3. Pull the primary model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PRIMARY_MODEL="phi3:mini"
echo ""
echo "ðŸ“¥ Pulling primary model: $PRIMARY_MODEL"
echo "   Size: ~2.5 GB | License: MIT"
echo "   This may take a few minutes on first run..."
echo ""

if ollama pull "$PRIMARY_MODEL"; then
    echo "âœ… Model '$PRIMARY_MODEL' downloaded successfully."
else
    echo "âš ï¸  Failed to pull '$PRIMARY_MODEL'. Trying fallback model..."
    FALLBACK_MODEL="qwen2.5:0.5b"
    echo "   Pulling fallback: $FALLBACK_MODEL (Size: ~0.6 GB)"
    if ollama pull "$FALLBACK_MODEL"; then
        echo "âœ… Fallback model '$FALLBACK_MODEL' downloaded."
        echo ""
        echo "âš ï¸  Update config/settings.yaml:"
        echo "    llm:"
        echo "      model: \"$FALLBACK_MODEL\""
    else
        echo "âŒ Both models failed to download. Check your internet connection."
        exit 1
    fi
fi

echo ""

# â”€â”€â”€ 4. Verify â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo "ðŸ” Verifying setup..."
echo ""
echo "Available models:"
ollama list
echo ""
echo "=============================================="
echo "  âœ… Setup complete!"
echo ""
echo "  Start the agent with:"
echo "    python -m openagent"
echo "=============================================="

# Kill the background ollama serve (systemd will manage it on Linux)
kill $OLLAMA_PID 2>/dev/null || true
